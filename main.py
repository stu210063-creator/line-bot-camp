import os
import sys
import threading
import time
import requests
import urllib.parse
import random
from bs4 import BeautifulSoup
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import (
    MessageEvent, TextMessage, TextSendMessage, FlexSendMessage
)

# ==========================================
# 1. ç³»çµ±è¨­å®šå€
# ==========================================
app = Flask(__name__)

# è®€å–ç’°å¢ƒè®Šæ•¸
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('LINE_CHANNEL_ACCESS_TOKEN')
LINE_CHANNEL_SECRET = os.environ.get('LINE_CHANNEL_SECRET')

# è‹¥æœ¬åœ°æ¸¬è©¦æ²’æœ‰è¨­å®šç’°å¢ƒè®Šæ•¸ï¼Œé˜²æ­¢å ±éŒ¯
if LINE_CHANNEL_ACCESS_TOKEN and LINE_CHANNEL_SECRET:
    line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
    handler = WebhookHandler(LINE_CHANNEL_SECRET)
else:
    print("âš ï¸ è­¦å‘Šï¼šæœªè¨­å®š LINE Tokenï¼ŒBot ç„¡æ³•é‹ä½œã€‚")

# å½è£æˆç€è¦½å™¨ï¼Œé¿å…è¢«ç¶²ç«™é˜»æ“‹
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

# å…¨åŸŸè³‡æ–™åº« (å­˜åœ¨è¨˜æ†¶é«”ä¸­)
# çµæ§‹: [{"title": "...", "url": "...", ...}]
CAMP_DATABASE = []
IS_UPDATING = False  # é–å®šæ¨™è¨˜ï¼Œé¿å…åŒæ™‚å¤šäººæŒ‰æ›´æ–°å°è‡´ç•¶æ©Ÿ

# ==========================================
# 2. çˆ¬èŸ²æ ¸å¿ƒé‚è¼¯
# ==========================================
class CampScraper:
    def __init__(self):
        self.data_list = []

    def fetch_all_in_background(self):
        """èƒŒæ™¯åŸ·è¡Œçˆ¬èŸ²ï¼Œä¸å¡ä½ LINE å›è¦†"""
        global CAMP_DATABASE, IS_UPDATING
        if IS_UPDATING:
            print("â³ çˆ¬èŸ²æ­£åœ¨åŸ·è¡Œä¸­ï¼Œè·³éæœ¬æ¬¡è«‹æ±‚...")
            return

        IS_UPDATING = True
        print("ğŸš€ é–‹å§‹èƒŒæ™¯æ›´æ–°è³‡æ–™åº«...")
        
        try:
            self.data_list = [] # æ¸…ç©ºæš«å­˜
            
            # 1. æŠ“å– KKTIX (é‡å°é«˜ä¸­/å¤§å­¸ç‡ŸéšŠ)
            self.scrape_kktix(keyword="å¤§å­¸ç‡ŸéšŠ")
            self.scrape_kktix(keyword="é«˜ä¸­é«”é©—ç‡Ÿ")
            self.scrape_kktix(keyword="é«˜ä¸­ç‡ŸéšŠ")
            
            # 2. æŠ“å– BeClass (é‡å°å­¸è¡“/å¿—å·¥)
            self.scrape_beclass(keyword="é«˜ä¸­ç‡ŸéšŠ")
            self.scrape_beclass(keyword="å¤§å­¸é«”é©—")

            # å»é™¤é‡è¤‡ç¶²å€
            unique_data = []
            seen_urls = set()
            for item in self.data_list:
                if item['url'] not in seen_urls:
                    unique_data.append(item)
                    seen_urls.add(item['url'])
            
            # æ›´æ–°å…¨åŸŸè³‡æ–™åº«
            if unique_data:
                random.shuffle(unique_data)
                CAMP_DATABASE = unique_data
                print(f"âœ… æ›´æ–°å®Œæˆï¼ç›®å‰å…±æœ‰ {len(CAMP_DATABASE)} ç­†è³‡æ–™ã€‚")
            else:
                print("âš ï¸ è­¦å‘Šï¼šæœ¬æ¬¡æ²’æœ‰æŠ“åˆ°ä»»ä½•è³‡æ–™ã€‚")
                
        except Exception as e:
            print(f"âŒ çˆ¬èŸ²ç™¼ç”Ÿè‡´å‘½éŒ¯èª¤: {e}")
        finally:
            IS_UPDATING = False

    def scrape_kktix(self, keyword):
        print(f"ğŸ” æœå°‹ KKTIX: {keyword}...")
        url = f"https://kktix.com/events?search={keyword}&start_at=2024-01-01&end_at=2026-12-31"
        try:
            res = requests.get(url, headers=HEADERS, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
            events = soup.select('ul.event-list > li')
            
            for event in events:
                try:
                    title = event.select_one('h2').get_text(strip=True)
                    link = event.select_one('a')['href']
                    if not link.startswith('http'): link = "https://kktix.com" + link
                    
                    time_tag = event.select_one('.date')
                    date_str = time_tag.get_text(strip=True) if time_tag else "è©³è¦‹å®˜ç¶²"
                    
                    # åœ–ç‰‡è™•ç†ï¼šå˜—è©¦æŠ“å–ï¼Œè‹¥ç„¡å‰‡çµ¦éš¨æ©Ÿåœ–
                    img_tag = event.select_one('img')
                    img_url = img_tag['src'] if img_tag else self.get_random_image()
                    
                    self.data_list.append({
                        "title": title,
                        "date": date_str,
                        "source": "KKTIX",
                        "url": link,
                        "image": img_url
                    })
                except: continue
        except Exception as e:
            print(f"KKTIX éŒ¯èª¤: {e}")

    def scrape_beclass(self, keyword):
        print(f"ğŸ” æœå°‹ BeClass: {keyword}...")
        # BeClass æœå°‹é€£çµ
        encoded = urllib.parse.quote(keyword)
        url = f"https://www.beclass.com/p/search.php?keyword={encoded}"
        
        try:
            res = requests.get(url, headers=HEADERS, timeout=15)
            # BeClass å®¹æ˜“æœ‰ç·¨ç¢¼å•é¡Œï¼Œå…ˆå˜—è©¦è‡ªå‹•åµæ¸¬
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # BeClass åˆ—è¡¨é …ç›®é€šå¸¸åœ¨ div.search_result_item_content æˆ–ç›´æ¥ a
            links = soup.find_all('a', href=True)
            
            count = 0
            for link in links:
                href = link['href']
                text = link.get_text(strip=True)
                
                # éæ¿¾æ¢ä»¶ï¼šä¸€å®šè¦åŒ…å« 'rid=' (é€™æ˜¯å ±åé ç‰¹å¾µ) ä¸”æ¨™é¡Œè¦åŒ…å«é—œéµå­—
                if 'rid=' in href and len(text) > 5 and ('ç‡Ÿ' in text or 'é«”é©—' in text):
                    if not href.startswith('http'): href = "https://www.beclass.com/" + href.lstrip('/')
                    
                    self.data_list.append({
                        "title": text,
                        "date": "è©³è¦‹ç°¡ç« ",
                        "source": "BeClass",
                        "url": href,
                        "image": self.get_random_image() # BeClass æ²’åœ–ï¼Œç›´æ¥çµ¦ç¾åœ–
                    })
                    count += 1
                    if count >= 10: break # é™åˆ¶æ•¸é‡ä»¥å…å¤ªå¤šé›œè¨Š
        except Exception as e:
            print(f"BeClass éŒ¯èª¤: {e}")

    def get_random_image(self):
        """æä¾›é«˜å“è³ªçš„éš¨æ©Ÿç‡ŸéšŠåœ–ç‰‡"""
        images = [
            "https://images.unsplash.com/photo-1523580494863-6f3031224c94?w=600&q=80", # å¤§å­¸
            "https://images.unsplash.com/photo-1517486808906-6ca8b3f04846?w=600&q=80", # è®€æ›¸
            "https://images.unsplash.com/photo-1503676260728-1c00da094a0b?w=600&q=80", # å­¸ç¿’
            "https://images.unsplash.com/photo-1531482615713-2afd69097998?w=600&q=80", # åœ˜éšŠ
            "https://images.unsplash.com/photo-1522202176988-66273c2fd55f?w=600&q=80"  # è¨è«–
        ]
        return random.choice(images)

# ==========================================
# 3. LINE Flex Message
# ==========================================
def create_flex_message(camps):
    bubbles = []
    # å–å‰ 12 ç­†é¡¯ç¤º
    for camp in camps[:12]:
        color = "#E64A19" if camp['source'] == "KKTIX" else "#1976D2"
        bubble = {
            "type": "bubble",
            "hero": {
                "type": "image", "url": camp['image'], "size": "full",
                "aspectRatio": "20:13", "aspectMode": "cover",
                "action": { "type": "uri", "uri": camp['url'] }
            },
            "body": {
                "type": "box", "layout": "vertical",
                "contents": [
                    { "type": "text", "text": camp['source'], "color": color, "weight": "bold", "size": "xs" },
                    { "type": "text", "text": camp['title'], "weight": "bold", "size": "sm", "wrap": True, "margin": "xs" },
                    { "type": "text", "text": camp['date'], "size": "xxs", "color": "#aaaaaa", "margin": "md" }
                ]
            },
            "footer": {
                "type": "box", "layout": "vertical",
                "contents": [
                    { "type": "button", "style": "primary", "height": "sm", "action": { "type": "uri", "label": "æŸ¥çœ‹å…§å®¹", "uri": camp['url'] } }
                ]
            }
        }
        bubbles.append(bubble)
    return FlexSendMessage(alt_text="ç‡ŸéšŠæœå°‹çµæœ", contents={"type": "carousel", "contents": bubbles})

# ==========================================
# 4. ä¼ºæœå™¨å…¥å£
# ==========================================
@app.route("/", methods=['GET'])
def home():
    return f"Bot Running. Database size: {len(CAMP_DATABASE)}"

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# å•Ÿå‹•æ™‚è‡ªå‹•è·‘ä¸€æ¬¡çˆ¬èŸ² (ä½¿ç”¨åŸ·è¡Œç·’ä»¥å…å¡ä½å•Ÿå‹•)
def initial_scrape():
    scraper = CampScraper()
    scraper.fetch_all_in_background()

# å•Ÿå‹•èƒŒæ™¯åŸ·è¡Œç·’
threading.Thread(target=initial_scrape).start()

@handler.add(MessageEvent, message=TextMessage)
def handle_message(event):
    msg = event.message.text.strip()
    
    # æŒ‡ä»¤ï¼šå¼·åˆ¶æ›´æ–°
    if msg == "æ›´æ–°":
        if IS_UPDATING:
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="ğŸ”„ ç³»çµ±æ­£åœ¨æ›´æ–°ä¸­ï¼Œè«‹ç¨å¾Œå†è©¦..."))
        else:
            # é–‹ä¸€å€‹æ–°åŸ·è¡Œç·’å»è·‘ï¼Œé¦¬ä¸Šå›è¦†ä½¿ç”¨è€…ï¼Œé¿å… LINE Timeout
            scraper = CampScraper()
            thread = threading.Thread(target=scraper.fetch_all_in_background)
            thread.start()
            line_bot_api.reply_message(event.reply_token, TextSendMessage(text="âš¡ æ”¶åˆ°æŒ‡ä»¤ï¼æ­£åœ¨å¾Œå°æœç´¢æœ€æ–°ç‡ŸéšŠè³‡è¨Š...\nè«‹ç´„ 30 ç§’å¾Œè¼¸å…¥ã€Œå¯’å‡ã€æŸ¥çœ‹çµæœã€‚"))
        return

    # æœå°‹é‚è¼¯
    found = []
    
    # æ¨¡ç³Šé—œéµå­—
    if msg in ["å¯’å‡", "ç‡ŸéšŠ", "é«˜ä¸­", "æ¨è–¦", "æ´»å‹•"]:
        found = CAMP_DATABASE
    else:
        # ç²¾ç¢ºæœå°‹
        for camp in CAMP_DATABASE:
            if msg in camp['title']:
                found.append(camp)

    if found:
        # éš¨æ©Ÿæ‰“äº‚çµæœï¼Œè®“ä½¿ç”¨è€…æ¯æ¬¡çœ‹åˆ°ä¸ä¸€æ¨£çš„
        random.shuffle(found)
        line_bot_api.reply_message(event.reply_token, create_flex_message(found))
    else:
        # æ‰¾ä¸åˆ°è³‡æ–™æ™‚çš„å›è¦†
        reply_txt = f"æ‰¾ä¸åˆ°ã€Œ{msg}ã€ç›¸é—œç‡ŸéšŠã€‚\nç›®å‰è³‡æ–™åº«æœ‰ {len(CAMP_DATABASE)} ç­†è³‡æ–™ã€‚\n\nğŸ’¡ å»ºè­°ï¼š\n1. è¼¸å…¥ã€Œæ›´æ–°ã€æŠ“å–æœ€æ–°è³‡æ–™\n2. è¼¸å…¥ã€Œå¯’å‡ã€æˆ–ã€Œé«˜ä¸­ã€æŸ¥çœ‹ç†±é–€æ´»å‹•"
        line_bot_api.reply_message(event.reply_token, TextSendMessage(text=reply_txt))

if __name__ == "__main__":
    app.run(port=5000)
